# Simple storage Service: S3

## Prefix
For the sake of organizational simplicity, the Amazon S3 console supports the folder concept as a means of grouping objects. Amazon S3 does this by using a shared name prefix for objects (that is, objects have names that begin with a common string). Object names are also referred to as  _key names_.

For example, you can create a folder on the console named  `photos`  and store an object named  `myphoto.jpg`  in it. The object is then stored with the key name  `photos/myphoto.jpg`, where  `photos/`  is the prefix.

Here are two more examples:

-   If you have three objects in your bucket—`logs/date1.txt`,  `logs/date2.txt`, and  `logs/date3.txt`—the console will show a folder named  `logs`. If you open the folder in the console, you will see three objects:  `date1.txt`,  `date2.txt`, and  `date3.txt`.
    
-   If you have an object named  `photos/2017/example.jpg`, the console will show you a folder named  `photos`  containing the folder  `2017`. The folder  `2017`  will contain the object  `example.jpg`.

1.  Each prefix can achieve up to 3,500/5,500 requests per second, so for many purposes, the  **assumption**  is that you wouldn't need to use several prefixes.
2.  Prefixes are considered to be the whole path (up to the last '/') of an object's location, and are no longer hashed only by the first 6-8 characters. Therefore it would be enough to just split the data between any two "folders" to achieve x2 max requests per second. (if requests are divided evenly between the two)


## S3 Glacier Archive Retrieval Options
-   **Expedited —**  Expedited retrievals allow you to quickly access your data when occasional urgent requests for a subset of archives are required. For all but the largest archives (250 MB+), data accessed using Expedited retrievals are typically made available within 1–5 minutes.
    
-   **Standard —**  Standard retrievals typically complete within 3–5 hours. This is the default option for retrieval.
    
-   **Bulk —**  Bulk retrievals are S3 Glacier’s lowest-cost retrieval option, which you can use to retrieve large amounts, even petabytes, of data inexpensively in a day. Bulk retrievals typically complete within 5–12 hours.

## Object lifecycle management
-   **Transition actions**—Define when objects transition to another  [storage class](https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html). For example, you might choose to transition objects to the S3 Standard-IA storage class 30 days after you created them, or archive objects to the S3 Glacier storage class one year after creating them.
    
-   **Expiration actions**—Define when objects expire. Amazon S3 deletes expired objects on your behalf.

## Hosting a static website using Amazon S3
To configure your bucket for static website hosting, you can use the AWS Management Console without writing any code. You can also create, update, and delete the website configuration  _programmatically_  by using the AWS SDKs. The SDKs provide wrapper classes around the Amazon S3 REST API. If your application requires it, you can send REST API requests directly from your application.

To host a static website on Amazon S3, you configure an Amazon S3 bucket for website hosting and then upload your website content to the bucket. When you configure a bucket as a static website, you must  [enable website hosting](https://docs.aws.amazon.com/AmazonS3/latest/dev/EnableWebsiteHosting.html),  [set permissions](https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteAccessPermissionsReqd.html), and  [create and add an index document](https://docs.aws.amazon.com/AmazonS3/latest/dev/IndexDocumentSupport.html). Depending on your website requirements, you can also configure  [redirects](https://docs.aws.amazon.com/AmazonS3/latest/dev/how-to-page-redirect.html),  [web traffic logging](https://docs.aws.amazon.com/AmazonS3/latest/dev/LoggingWebsiteTraffic.html), and a  [custom error document](https://docs.aws.amazon.com/AmazonS3/latest/dev/CustomErrorDocSupport.html).

After you configure your bucket as a static website, you can access the bucket through the AWS Region-specific Amazon S3 website endpoints for your bucket. Website endpoints are different from the endpoints where you send REST API requests. For more information, see  [Website endpoints](https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteEndpoints.html). Amazon S3 doesn't support HTTPS access for website endpoints. If you want to use HTTPS, you can use CloudFront to serve a static website hosted on Amazon S3. For more information, see  [Speeding up your website with Amazon CloudFront](https://docs.aws.amazon.com/AmazonS3/latest/dev/website-hosting-cloudfront-walkthrough.html).

## Uploading objects using presigned URLs

A presigned URL gives you access to the object identified in the URL, provided that the creator of the presigned URL has permissions to access that object. That is, if you receive a presigned URL to upload an object, you can upload the object only if the creator of the presigned URL has the necessary permissions to upload that object.

All objects and buckets by default are private. The presigned URLs are useful if you want your user/customer to be able to upload a specific object to your bucket, but you don't require them to have AWS security credentials or permissions.

When you create a presigned URL, you must provide your security credentials and then specify a bucket name, an object key, an HTTP method (PUT for uploading objects), and an expiration date and time. The presigned URLs are valid only for the specified duration. That is, you must start the action before the expiration date and time. If the action consists of multiple steps, such as a multipart upload, all steps must be started before the expiration, otherwise you will receive an error when Amazon S3 attempts to start a step with an expired URL.

## Best Practices Design Patterns: Optimizing Amazon S3 Performance

Amazon S3 automatically scales to high request rates. For example, your application can achieve at least 3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per  [prefix](https://docs.aws.amazon.com/general/latest/gr/glos-chap.html#keyprefix)  in a bucket. There are no limits to the number of prefixes in a bucket. You can increase your read or write performance by parallelizing reads. For example, if you create 10 prefixes in an Amazon S3 bucket to parallelize reads, you could scale your read performance to 55,000 read requests per second.

Some data lake applications on Amazon S3 scan millions or billions of objects for queries that run over petabytes of data. These data lake applications achieve single-instance transfer rates that maximize the network interface use for their  [Amazon EC2](https://docs.aws.amazon.com/ec2/index.html)  instance, which can be up to 100 Gb/s on a single instance. These applications then aggregate throughput across multiple instances to get multiple terabits per second.

Other applications are sensitive to latency, such as social media messaging applications. These applications can achieve consistent small object latencies (and first-byte-out latencies for larger objects) of roughly 100–200 milliseconds.

Other AWS services can also help accelerate performance for different application architectures. For example, if you want higher transfer rates over a single HTTP connection or single-digit millisecond latencies, use  [Amazon CloudFront](https://docs.aws.amazon.com/cloudfront/index.html)  or  [Amazon ElastiCache](https://docs.aws.amazon.com/elasticache/index.html)  for caching with Amazon S3.


## Encryption
-   SSE-S3 – Server Side Encryption with S3 managed keys.
    -   Each object is encrypted with a unique key.
    -   Encryption key is encrypted with a master key.
    -   AWS regularly rotate the master key.
    -   Uses AES 256.
-   SSE-KMS – Server Side Encryption with AWS KMS keys.
    -   KMS uses Customer Master Keys (CMKs) to encrypt.
    -   Can use the automatically created CMK key.
    -   OR you can select your own key (gives you control for management of keys).
    -   An envelope key protects your keys.
    -   Chargeable.
-   SSE-C – Server Side Encryption with client provided keys.
    -   Client manages the keys, S3 manages encryption.
    -   AWS does not store the encryption keys.
    -   If keys are lost data cannot be decrypted.

Notes: https://digitalcloud.training/certification-training/aws-solutions-architect-associate/storage/amazon-s3/
